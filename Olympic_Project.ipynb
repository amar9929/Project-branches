{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Olympic Project - road to gold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    " 1. How has the performance of athletes changed based on gender, and has this led to a reduction in the performance gap?\n",
    " 2. Can past Olympic results reliably predict future outcomes?\n",
    "\n",
    "## Hypothesis:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. As women have increasingly engaged in the Olympic Games and gained more equitable chances to train and compete, the performance gap should have diminished over the last century and is expected to continue decreasing in every competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-How has the performance of athletes changed based on gender, and has this led to a reduction in the performance gap?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Olympic performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import of the data frame\n",
    "from selenium import webdriver \n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the imformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_extraction(soup):\n",
    "    ''' this function extract the information of a specifique event from the olympic web page using web scrapping\n",
    "    '''\n",
    "    \n",
    "    #location and indentification of the required information\n",
    "    table = soup.find('div',attrs={'data-cy':'table-content'})\n",
    "    rows = table.find_all('div',attrs={'data-row-id':True})\n",
    "    #list of the info to capture\n",
    "    countries = []\n",
    "    participant=[]\n",
    "    results=[]\n",
    "    #loop to extract all events information of the dicipline selected\n",
    "    for row in rows:\n",
    "        try:\n",
    "            countries.append(row.find('span',attrs={'class':'styles__CountryName-sc-1r5phm6-1 eQULfE'}).text)\n",
    "        except:\n",
    "            countries.append(None)\n",
    "        try:\n",
    "            participant.append(row.find('h3',attrs={'data-cy':'athlete-name'}).text)\n",
    "        except:\n",
    "            participant.append(None)\n",
    "        try:\n",
    "            results.append(row.find('span',attrs={'data-cy':'result-info-content'}).text)\n",
    "        except:\n",
    "            results.append(None)\n",
    "    info_event=pd.DataFrame({'country':countries,'participant':participant,'result':results})\n",
    "    #add a column with the olympics games name\n",
    "    olympicg= soup.find('button',attrs={'data-cy':'game-select'}).text\n",
    "    info_event['olympic_game']=olympicg\n",
    "    #add a column with the dicipline name\n",
    "    discipline=soup.find('button',attrs={'data-cy':'discipline-select'}).text\n",
    "    info_event['discipline']=discipline\n",
    "    #add a column with the event name\n",
    "    event=soup.find('button',attrs={'data-cy':'event-select'}).text\n",
    "    info_event['event']=event\n",
    "    #return the entire dataset with all the required information\n",
    "    return info_event\n",
    "\n",
    "def data_grab(url):\n",
    "    ''' from the url of a specific discipline at the select olympic game, this function upload the pages of all event to be able to extract the information.\n",
    "    It return a csv files in order to use the information later.'''\n",
    "    #create the list with the required information\n",
    "    final_result=[]\n",
    "    #calculate the number of event in the dicipline selected\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    button_event = driver.find_element('css selector','button[data-cy=event-select]')\n",
    "    button_event.click()\n",
    "    events = len(driver.find_elements('css selector','button[data-cy=event-button]'))\n",
    "    button_event.click()\n",
    "    #loop to go though all the url and grab the required information or print the url where it did't work\n",
    "    try:    \n",
    "        for i in range(11,events):\n",
    "            button_event = driver.find_element('css selector','button[data-cy=event-select]')\n",
    "            button_event.click()\n",
    "            eventfor=driver.find_elements('css selector','button[data-cy=event-button]')\n",
    "            eventfor=eventfor[i]\n",
    "            eventfor.click()\n",
    "            #Go to the result of the event selected\n",
    "            button_go = driver.find_element('css selector','a[data-cy=go-link]')\n",
    "            try:\n",
    "                button_go.click()\n",
    "            except:\n",
    "                driver.get(button_go.get_attribute('href'))  \n",
    "            time.sleep(5)\n",
    "            soup= BeautifulSoup(driver.page_source)\n",
    "            final_result.append(info_extraction(soup))\n",
    "        pd.concat(final_result).to_csv(url.split('olympic-games/')[1].replace('/','_')+'.csv')\n",
    "    except Exception as error:\n",
    "        print(error)        \n",
    "        print(url)\n",
    "        return final_result\n",
    "\n",
    "def check_valid_urls(urls):\n",
    "    \"\"\"Removes urls from the list that have a 400 status\n",
    "        Parameters:\n",
    "            urls- a iterable with url in string format\n",
    "        Return:\n",
    "            a list of working urls\n",
    "    \"\"\"\n",
    "    driver = webdriver.Chrome()\n",
    "    valid_urls=[]\n",
    "    for url in urls:\n",
    "        driver.get(url)\n",
    "        if not driver.current_url.endswith('404.html'):\n",
    "            valid_urls.append(url)\n",
    "    return valid_urls.to_csv('olympics_url'+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extracting code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list=pd.read_csv('olympics_url.csv').iloc[:,1].to_list()\n",
    "w_list=[fil for fil in url_list if fil.endswith('weightlifting')]\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://olympics.com/en/olympic-games/beijing-2022/results/alpine-skiing')\n",
    "time.sleep(5)\n",
    "cookies_button = driver.find_element('css selector','#onetrust-accept-btn-handler')\n",
    "cookies_button.click()\n",
    "time.sleep(5)\n",
    "list(map(data_grab,w_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the event with comparable result\n",
    "csv_list = [pd.read_csv('../Project-branches/Data events/'+fil) for fil in os.listdir('../Project-branches/Data events/') if fil.endswith('swimming.csv') or fil.endswith('weightlifting.csv') or fil.endswith('athletics.csv')\n",
    "             or fil.endswith('cycling-track.csv') or fil.endswith('rowing.csv') or fil.endswith('sailing.csv')\n",
    "             ]\n",
    "data_olympic=pd.concat(csv_list)\n",
    "data_olympic.rename(columns={'Unnamed: 0': 'rank'},inplace=True)\n",
    "#drop rows if result==nan\n",
    "data_olympic.dropna(subset='result',inplace=True)\n",
    "#divide olympic_game columns into two columns olympic_host and olympic_game_year\n",
    "data_olympic['olympic_host']=data_olympic['olympic_game'].str.split(' ').str[0]\n",
    "data_olympic['olympic_game_year']=data_olympic['olympic_game'].str.split(' ').str[1]\n",
    "data_olympic.drop(columns='olympic_game',inplace=True)\n",
    "data_olympic['olympic_host']=data_olympic['olympic_host'].str.replace('Los','Los Angeles').str.replace('Mexico','Mexico City') #Manual solution :(\n",
    "data_olympic['olympic_game_year']=data_olympic['olympic_game_year'].str.replace('Angeles','1984').str.replace('City','1968') #Manual solution :(\n",
    "#create and separete by gender using column event and drop rows of mix events\n",
    "data_olympic['gender'] = data_olympic['event'].apply(lambda x: re.findall(r'\\b(men|women)\\b', x, flags=re.IGNORECASE)[0].lower() if re.findall(r'\\b(men|women)\\b', x, flags=re.IGNORECASE) else 'mix')\n",
    "data_olympic=data_olympic[data_olympic['gender']!='mix']\n",
    "#cleaning event\n",
    "data_olympic['event'] = data_olympic['event'].apply(lambda x: re.sub(r'\\b(?:men|women)\\b', '', x, flags=re.IGNORECASE).lower().strip())\n",
    "data_olympic['event']=data_olympic['event'].str.replace(\"'s\",'',)\n",
    "#filter by rank\n",
    "data_olympic=data_olympic[data_olympic['rank']<=2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(data_olympic,index=['discipline','event'],columns='gender',values='result',aggfunc='count').sort_values(by='women',ascending=False).head(20) #this can be a function that give you this list or dict with x top events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating comparable tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first event\n",
    "relay400=data_olympic[data_olympic['event']=='4x100m relay']\n",
    "relay400['result']=relay400['result'].str.replace('w','')\n",
    "relay400['result']=relay400['result'].astype(float)\n",
    "relay400s=pd.pivot_table(relay400, index=['olympic_game_year'], columns='gender', values='result', aggfunc='mean')\n",
    "relay400s['gap']=relay400s['men']-relay400s['women']\n",
    "relay400s.round(2).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second event\n",
    "free100=data_olympic[data_olympic['event']=='100m']\n",
    "free100['result']=free100['result'].str.replace('w','')\n",
    "free100['result']=free100['result'].astype(float)\n",
    "free100s=pd.pivot_table(free100, index=['olympic_game_year'], columns='gender', values='result', aggfunc='mean')\n",
    "free100s['gap']=free100s['men']-free100s['women']\n",
    "free100s.round(2).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#third event\n",
    "high_jump=data_olympic[data_olympic['event']=='high jump']\n",
    "high_jump['result']=high_jump['result'].astype(float)\n",
    "high_jump_sum=pd.pivot_table(high_jump, index=['olympic_game_year'], columns='gender', values='result', aggfunc='mean')\n",
    "high_jump_sum['gap']=high_jump_sum['men']-high_jump_sum['women']\n",
    "high_jump_sum.round(2).sort_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
